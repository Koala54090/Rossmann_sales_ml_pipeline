# -*- coding: utf-8 -*-
"""Rossmann_Store_Sales_ML_Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UCVqfz47SyYCgT94b9OXi_z2-QMzzqlt
"""

# LEAKAGE-SAFE END-TO-END PIPELINE
#Imports
import numpy as np
import pandas as pd
from pathlib import Path

from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

from xgboost import XGBRegressor

RANDOM_STATE = 42

#Load Data
DATA_PATH = Path("./data")

train = pd.read_csv("train.csv", parse_dates=["Date"])
stores = pd.read_csv("store.csv")

df = train.merge(stores, on="Store", how="left")

# ----- Standardize Columns -----
df.columns = df.columns.str.lower().str.strip().str.replace(" ", "_")

# ----- Date Features -----
df["year"] = df["date"].dt.year
df["month"] = df["date"].dt.month
df["year_month"] = df["date"].dt.to_period("M").dt.to_timestamp()

# ----- Type Cleaning -----
bool_cols = ["promo", "open", "schoolholiday"]
for col in bool_cols:
    df[col] = df[col].astype("boolean")

df["stateholiday"] = df["stateholiday"].replace({"0": "none"}).astype("category")

# ----- Monthly Aggregation -----
dm = (
    df.groupby(["store", "year_month"], as_index=False)
      .agg(
          gross=("sales", "sum"),
          avg_customers=("customers", "mean"),
          promo_rate=("promo", "mean"),
          holiday_rate=("schoolholiday", "mean"),
          avg_competition_distance=("competitiondistance", "mean"),
          avg_open=("open", "mean"),
      )
      .sort_values(["store", "year_month"])
)

# ----- Seasonality -----
dm["month_num"] = dm["year_month"].dt.month
dm["sin_month"] = np.sin(2 * np.pi * dm["month_num"] / 12)
dm["cos_month"] = np.cos(2 * np.pi * dm["month_num"] / 12)

# ----- Lag & Rolling Features -----
def add_lags(g):
    g = g.sort_values("year_month").copy()
    g["lag1_sales"] = g["gross"].shift(1)
    g["lag2_sales"] = g["gross"].shift(2)
    g["lag3_sales"] = g["gross"].shift(3)
    g["rolling_mean_3m"] = g["gross"].shift(1).rolling(3).mean()
    g["rolling_std_3m"] = g["gross"].shift(1).rolling(3).std()
    return g

dm = dm.groupby("store", group_keys=False).apply(add_lags)

feat = dm.dropna().reset_index(drop=True)

# ----- Time-Based Train/Test Split -----
unique_months = feat["year_month"].drop_duplicates().sort_values()
cutoff = int(len(unique_months) * 0.8)

train_months = unique_months[:cutoff]
test_months = unique_months[cutoff:]

train_df = feat[feat["year_month"].isin(train_months)]
test_df = feat[feat["year_month"].isin(test_months)]

# ----- Features & Target -----
TARGET = "gross"

num_cols = [
    "avg_customers",
    "promo_rate",
    "holiday_rate",
    "avg_competition_distance",
    "avg_open",
    "month_num",
    "sin_month",
    "cos_month",
    "lag1_sales",
    "lag2_sales",
    "lag3_sales",
    "rolling_mean_3m",
    "rolling_std_3m"
]

cat_cols = ["store"]

X_train = train_df[num_cols + cat_cols]
y_train = train_df[TARGET]

X_test = test_df[num_cols + cat_cols]
y_test = test_df[TARGET]

# ----- Preprocessing Pipeline (LEAKAGE SAFE) -----
preprocessor = ColumnTransformer(
    transformers=[
        ("num", Pipeline([
            ("impute", SimpleImputer(strategy="median")),
            ("scale", StandardScaler())
        ]), num_cols),
        ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), cat_cols)
    ]
)

# ----- Models -----
models = {
    "Linear Regression": Pipeline([
        ("prep", preprocessor),
        ("mdl", LinearRegression())
    ]),
    "Ridge": Pipeline([
        ("prep", preprocessor),
        ("mdl", Ridge(alpha=1.0))
    ]),
    "Random Forest": Pipeline([
        ("prep", preprocessor),
        ("mdl", RandomForestRegressor(
            n_estimators=200,
            max_depth=10,
            random_state=RANDOM_STATE,
            n_jobs=-1
        ))
    ]),
    "XGBoost": Pipeline([
        ("prep", preprocessor),
        ("mdl", XGBRegressor(
            n_estimators=300,
            learning_rate=0.05,
            max_depth=6,
            random_state=RANDOM_STATE,
            n_jobs=-1,
            verbosity=0
        ))
    ])
}

# ----- Train & Evaluate -----
results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)

    rmse = np.sqrt(mean_squared_error(y_test, preds))
    r2 = r2_score(y_test, preds)

    results[name] = {"RMSE": rmse, "R2": r2}
    print(f"{name:20} RMSE: {rmse:,.0f} | RÂ²: {r2:.3f}")

pd.DataFrame(results).T.sort_values("RMSE")